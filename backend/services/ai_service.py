"""
AI åˆ†ææœåŠ¡æ¨¡å—

æœ¬æ–‡ä»¶æä¾› AI è‚¡ç¥¨åˆ†ææœåŠ¡ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æä¾›å•†ï¼š
- OpenAI (GPT)
- DeepSeek
- Kimi (æœˆä¹‹æš—é¢)
- é€šä¹‰åƒé—® (Qwen)
- Grok (xAI)
- Gemini (Google)
- Claude (Anthropic)
- è±†åŒ… (å­—èŠ‚è·³åŠ¨)
- GLM (æ™ºè°±)

ä¸»è¦åŠŸèƒ½ï¼š
1. get_models(): è·å–æŒ‡å®šæä¾›å•†çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
2. call_llm(): è°ƒç”¨ LLM è¿›è¡Œåˆ†æ
3. call_llm_with_signal(): è°ƒç”¨ LLM å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ
4. format_data_for_prompt(): æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®ä¸ºæç¤ºè¯
"""

import json
import time
import logging
import re
from typing import Dict, Any, List, Optional

import requests

from providers import PROVIDER_REGISTRY, get_protocol, get_provider_list

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é”™è¯¯ç æ˜ å°„
ERROR_MESSAGES = {
    429: "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼ŒAPI é…é¢å·²ç”¨å°½ã€‚è¯·ç¨åå†è¯•æˆ–æ›´æ¢æ¨¡å‹",
    401: "API Key æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥é…ç½®",
    403: "API Key æƒé™ä¸è¶³æˆ–è¢«ç¦ç”¨",
    404: "æ¨¡å‹ä¸å­˜åœ¨æˆ– API è·¯å¾„é”™è¯¯",
    500: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
    503: "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•",
}


class AIService:
    """
    AI åˆ†ææœåŠ¡
    
    æä¾›ç»Ÿä¸€çš„ AI æ¨¡å‹è°ƒç”¨æ¥å£ï¼Œæ”¯æŒå¤šç§æä¾›å•†
    """
    
    @staticmethod
    def get_providers() -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ”¯æŒçš„æä¾›å•†åˆ—è¡¨
        
        Returns:
            æä¾›å•†åˆ—è¡¨ï¼Œç”¨äºå‰ç«¯å±•ç¤º
        """
        return get_provider_list()
    
    @staticmethod
    def get_models(provider: str, api_key: str, proxy: str = None) -> List[Dict]:
        """
        è·å–æŒ‡å®šæä¾›å•†çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
        
        Args:
            provider: æä¾›å•† IDï¼ˆå¦‚ openaiã€deepseekã€gemini ç­‰ï¼‰
            api_key: API Key
            proxy: ä»£ç†åœ°å€
            
        Returns:
            æ¨¡å‹åˆ—è¡¨ [{"id": "model-id", "name": "Model Name"}, ...]
        """
        try:
            # å…¼å®¹æ—§çš„ provider åç§°
            provider_id = provider.lower()
            if provider_id == "gpt":
                provider_id = "openai"
            
            # è·å–æä¾›å•†é…ç½®
            config = PROVIDER_REGISTRY.get(provider_id)
            if not config:
                logger.warning(f"æœªçŸ¥çš„æä¾›å•†: {provider}")
                return []
            
            # è·å–åè®®å®ä¾‹
            protocol = get_protocol(config.protocol)
            if not protocol:
                logger.warning(f"æœªçŸ¥çš„åè®®: {config.protocol}")
                return config.default_models or []
            
            # è°ƒç”¨åè®®è·å–æ¨¡å‹åˆ—è¡¨
            return protocol.get_models(config, api_key, proxy)
            
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    @staticmethod
    def call_llm(
        provider: str,
        api_key: str,
        model: str,
        prompt: str,
        proxy: str = None,
        max_retries: int = 3,
    ) -> str:
        """
        è°ƒç”¨ LLM API
        
        Args:
            provider: æä¾›å•† ID
            api_key: API Key
            model: æ¨¡å‹ ID
            prompt: ç”¨æˆ·æç¤ºè¯
            proxy: ä»£ç†åœ°å€
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            
        Returns:
            æ¨¡å‹å›å¤æ–‡æœ¬
        """
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿æŠ€æœ¯é¢åˆ†æå’ŒåŸºæœ¬é¢åˆ†æã€‚è¯·æ ¹æ®æä¾›çš„è‚¡ç¥¨æ•°æ®ï¼Œç»™å‡ºä¸“ä¸šçš„è¶‹åŠ¿é¢„æµ‹å’Œæ“ä½œå»ºè®®ã€‚é‡ç‚¹å…³æ³¨æˆäº¤é‡å˜åŒ–ä¸ä»·æ ¼èµ°åŠ¿çš„é…åˆå…³ç³»ã€‚è¾“å‡ºæ ¼å¼ä½¿ç”¨Markdownã€‚"
        
        # å…¼å®¹æ—§çš„ provider åç§°
        provider_id = provider.lower()
        if provider_id == "gpt":
            provider_id = "openai"
        
        # è·å–æä¾›å•†é…ç½®
        config = PROVIDER_REGISTRY.get(provider_id)
        if not config:
            return f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}"
        
        # è·å–åè®®å®ä¾‹
        protocol = get_protocol(config.protocol)
        if not protocol:
            return f"æœªçŸ¥çš„åè®®: {config.protocol}"
        
        last_error = None
        for attempt in range(max_retries):
            try:
                return protocol.chat(config, api_key, model, system_prompt, prompt, proxy)
                
            except requests.exceptions.HTTPError as e:
                last_error = e
                status_code = getattr(getattr(e, "response", None), "status_code", 0)
                friendly_msg = ERROR_MESSAGES.get(status_code, f"HTTP é”™è¯¯ {status_code}")
                logger.error(f"LLMè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {friendly_msg}")
                
                if status_code == 429 and attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    continue
                return f"åˆ†æå¤±è´¥: {friendly_msg}"
                
            except requests.exceptions.ProxyError as e:
                return f"åˆ†æå¤±è´¥: ä»£ç†è¿æ¥å¤±è´¥ï¼ˆå½“å‰: {proxy}ï¼‰"
                
            except requests.exceptions.ConnectionError as e:
                error_str = str(e)
                if "ProxyError" in error_str or "proxy" in error_str.lower():
                    return f"åˆ†æå¤±è´¥: ä»£ç†è¿æ¥å¤±è´¥"
                return f"åˆ†æå¤±è´¥: ç½‘ç»œè¿æ¥å¤±è´¥"
                
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    time.sleep(2)
                    continue
                return "åˆ†æå¤±è´¥: è¯·æ±‚è¶…æ—¶"
                
            except Exception as e:
                return f"åˆ†æå¤±è´¥: {str(e)}"
        
        return f"åˆ†æå¤±è´¥: é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥"
    
    @staticmethod
    def call_llm_with_signal(
        provider: str,
        api_key: str,
        model: str,
        prompt: str,
        proxy: str = None,
        max_retries: int = 3,
        is_precise: bool = False,
        current_price: float = 0,
        future_dates: List[str] = None,
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ LLM å¹¶è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            provider: æä¾›å•† ID
            api_key: API Key
            model: æ¨¡å‹ ID
            prompt: ç”¨æˆ·æç¤ºè¯
            proxy: ä»£ç†åœ°å€
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            is_precise: æ˜¯å¦ç²¾å‡†åˆ†æ
            current_price: å½“å‰ä»·æ ¼
            future_dates: æœªæ¥æ—¥æœŸåˆ—è¡¨
            
        Returns:
            {"result": str, "signal": str, "summary": str, "prediction": list}
        """
        # æ„å»ºç»“æ„åŒ–è¾“å‡ºè¦æ±‚
        if is_precise and future_dates:
            structured_prompt = prompt + f"""

### è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·åœ¨åˆ†æç»“æŸåï¼Œé¢å¤–è¾“å‡ºä¸€ä¸ª JSON å—ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{{
  "signal": "bullish/cautious/bearish",
  "summary": "ä¸€å¥è¯æ€»ç»“ï¼ˆ50å­—ä»¥å†…ï¼‰",
  "prediction": [
    {{"date": "{future_dates[0]}", "price": é¢„æµ‹ä»·æ ¼, "change_pct": ç›¸å¯¹å½“å‰ä»·æ¶¨è·Œå¹…}},
    {{"date": "{future_dates[1]}", "price": é¢„æµ‹ä»·æ ¼, "change_pct": ç›¸å¯¹å½“å‰ä»·æ¶¨è·Œå¹…}},
    {{"date": "{future_dates[2]}", "price": é¢„æµ‹ä»·æ ¼, "change_pct": ç›¸å¯¹å½“å‰ä»·æ¶¨è·Œå¹…}},
    {{"date": "{future_dates[3]}", "price": é¢„æµ‹ä»·æ ¼, "change_pct": ç›¸å¯¹å½“å‰ä»·æ¶¨è·Œå¹…}},
    {{"date": "{future_dates[4]}", "price": é¢„æµ‹ä»·æ ¼, "change_pct": ç›¸å¯¹å½“å‰ä»·æ¶¨è·Œå¹…}}
  ]
}}
```

å½“å‰ä»·æ ¼: {current_price}

signal å–å€¼è¯´æ˜ï¼š
- bullish: çœ‹æ¶¨ï¼Œå»ºè®®ä¹°å…¥æˆ–æŒæœ‰
- cautious: è°¨æ…ï¼Œå»ºè®®è§‚æœ›
- bearish: çœ‹è·Œï¼Œå»ºè®®å–å‡ºæˆ–å‡ä»“

prediction è¯´æ˜ï¼š
- è¯·æ ¹æ®æŠ€æœ¯åˆ†æå’ŒåŸºæœ¬é¢åˆ†æï¼Œé¢„æµ‹æœªæ¥5ä¸ªäº¤æ˜“æ—¥çš„ä»·æ ¼èµ°åŠ¿
- price: é¢„æµ‹çš„æ”¶ç›˜ä»·ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰
- change_pct: ç›¸å¯¹äºå½“å‰ä»·æ ¼çš„æ¶¨è·Œå¹…ç™¾åˆ†æ¯”ï¼ˆä¿ç•™2ä½å°æ•°ï¼‰
"""
        else:
            structured_prompt = prompt + """

### è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·åœ¨åˆ†æç»“æŸåï¼Œé¢å¤–è¾“å‡ºä¸€ä¸ª JSON å—ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
{
  "signal": "bullish/cautious/bearish",
  "summary": "ä¸€å¥è¯æ€»ç»“ï¼ˆ50å­—ä»¥å†…ï¼‰"
}
```

signal å–å€¼è¯´æ˜ï¼š
- bullish: çœ‹æ¶¨ï¼Œå»ºè®®ä¹°å…¥æˆ–æŒæœ‰
- cautious: è°¨æ…ï¼Œå»ºè®®è§‚æœ›
- bearish: çœ‹è·Œï¼Œå»ºè®®å–å‡ºæˆ–å‡ä»“
"""
        
        # è°ƒç”¨ LLM
        result = AIService.call_llm(provider, api_key, model, structured_prompt, proxy, max_retries)
        
        # æ£€æŸ¥æ˜¯å¦å¤±è´¥
        if result.startswith("åˆ†æå¤±è´¥"):
            return {
                "result": result,
                "signal": "cautious",
                "summary": "",
                "prediction": []
            }
        
        # æå–ä¿¡å·
        signal_data = AIService.extract_signal_from_result(result)
        
        # æå–é¢„æµ‹æ•°æ®
        prediction = []
        if is_precise and current_price > 0:
            prediction = AIService.extract_prediction_from_result(result, current_price)
        
        return {
            "result": result,
            "signal": signal_data["signal"],
            "summary": signal_data["summary"],
            "prediction": prediction
        }
    
    @staticmethod
    def extract_signal_from_result(result: str) -> Dict[str, str]:
        """
        ä»åˆ†æç»“æœä¸­æå–ä¿¡å·å’Œæ‘˜è¦
        
        Args:
            result: LLM è¿”å›çš„åˆ†æç»“æœ
            
        Returns:
            {"signal": "bullish/cautious/bearish", "summary": "..."}
        """
        # å°è¯•ä»ç»“æœä¸­æå– JSON å—
        json_pattern = r'```json\s*(\{[^`]+\})\s*```'
        match = re.search(json_pattern, result, re.DOTALL)
        if match:
            try:
                data = json.loads(match.group(1))
                return {
                    "signal": data.get("signal", "cautious"),
                    "summary": data.get("summary", "")[:100]
                }
            except:
                pass
        
        # å°è¯•ç›´æ¥è§£æ JSON
        json_inline = r'\{\s*"signal"\s*:\s*"(\w+)"\s*,\s*"summary"\s*:\s*"([^"]+)"\s*\}'
        match = re.search(json_inline, result)
        if match:
            return {
                "signal": match.group(1),
                "summary": match.group(2)[:100]
            }
        
        # å…³é”®è¯åŒ¹é…ä½œä¸ºåå¤‡æ–¹æ¡ˆ
        result_lower = result.lower()
        signal = "cautious"
        
        bullish_keywords = ["çœ‹æ¶¨", "ä¹°å…¥", "å¼ºåŠ¿", "çªç ´", "ä¸Šæ¶¨", "bullish", "buy", "å»ºè®®ä¹°å…¥", "é€¢ä½ä¹°å…¥"]
        bearish_keywords = ["çœ‹è·Œ", "å–å‡º", "å¼±åŠ¿", "ä¸‹è·Œ", "bearish", "sell", "å»ºè®®å–å‡º", "å‡ä»“"]
        
        bullish_count = sum(1 for kw in bullish_keywords if kw in result_lower)
        bearish_count = sum(1 for kw in bearish_keywords if kw in result_lower)
        
        if bullish_count > bearish_count + 1:
            signal = "bullish"
        elif bearish_count > bullish_count + 1:
            signal = "bearish"
        
        # æå–æ‘˜è¦
        lines = [l.strip() for l in result.split('\n') if l.strip() and not l.startswith('#')]
        summary = lines[0][:100] if lines else "åˆ†æå®Œæˆ"
        
        return {"signal": signal, "summary": summary}
    
    @staticmethod
    def extract_prediction_from_result(result: str, current_price: float) -> List[Dict]:
        """
        ä»åˆ†æç»“æœä¸­æå–ä»·æ ¼é¢„æµ‹æ•°æ®
        
        Args:
            result: LLM è¿”å›çš„åˆ†æç»“æœ
            current_price: å½“å‰ä»·æ ¼
            
        Returns:
            [{"date": "2025-12-16", "price": 44.5, "change_pct": 2.2}, ...]
        """
        # å°è¯•ä»ç»“æœä¸­æå– prediction JSON å—
        json_pattern = r'```json\s*(\{[^`]*"prediction"[^`]*\})\s*```'
        match = re.search(json_pattern, result, re.DOTALL)
        if match:
            try:
                data = json.loads(match.group(1))
                if "prediction" in data and isinstance(data["prediction"], list):
                    return data["prediction"]
            except:
                pass
        
        # å°è¯•åŒ¹é…ç‹¬ç«‹çš„ prediction æ•°ç»„
        pred_pattern = r'"prediction"\s*:\s*\[(.*?)\]'
        match = re.search(pred_pattern, result, re.DOTALL)
        if match:
            try:
                pred_str = "[" + match.group(1) + "]"
                predictions = json.loads(pred_str)
                if predictions:
                    return predictions
            except:
                pass
        
        return []
    
    @staticmethod
    def _format_volume(vol: int) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡ä¸ºæ˜“è¯»æ ¼å¼"""
        if vol >= 100000000:
            return f"{vol / 100000000:.2f}äº¿"
        elif vol >= 10000:
            return f"{vol / 10000:.2f}ä¸‡"
        return str(vol)
    
    @staticmethod
    def format_data_for_prompt(
        basic: Dict,
        minute_data: List[Dict],
        kline_data: List[Dict],
        extra_info: Optional[Dict] = None,
        market_data: Optional[Dict] = None,
        trade_history: Optional[List[Dict]] = None,
        ai_history: Optional[List[Dict]] = None,
        money_flow: Optional[List[Dict]] = None,
        money_flow_days: int = 2,
        extra_data: Optional[Dict] = None,
        dragon_tiger: Optional[List[Dict]] = None,
    ) -> str:
        """
        å°†è‚¡ç¥¨æ•°æ®æ ¼å¼åŒ–ä¸º LLM æç¤ºè¯
        
        é‡ç‚¹çªå‡ºæˆäº¤é‡å’Œèµ„é‡‘æµå‘ä¿¡æ¯ï¼ŒåŒ…å«ç”¨æˆ·äº¤æ˜“è®°å½•å’Œå†å² AI åˆ†æè®°å½•
        
        Args:
            basic: è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            minute_data: åˆ†æ—¶æ•°æ®
            kline_data: Kçº¿æ•°æ®
            extra_info: ç”¨æˆ·é™„åŠ ä¿¡æ¯ï¼ˆæŒä»“æˆæœ¬ã€æ­¢ç›ˆæ­¢æŸç­‰ï¼‰
            market_data: å¤§ç›˜æ•°æ®
            trade_history: ç”¨æˆ·äº¤æ˜“è®°å½•
            ai_history: å†å² AI åˆ†æè®°å½•
            money_flow: èµ„é‡‘æµå‘æ•°æ®
            money_flow_days: èµ„é‡‘æµå‘å¤©æ•°
            extra_data: é¢å¤–æ•°æ®ï¼ˆæ¢æ‰‹ç‡ã€é‡æ¯”ã€å‡çº¿ç­‰ï¼‰
            dragon_tiger: é¾™è™æ¦œæ•°æ®
            
        Returns:
            æ ¼å¼åŒ–åçš„æç¤ºè¯
        """
        prompt_parts = []
        
        # 1. åŸºæœ¬ä¿¡æ¯
        prompt_parts.append(f"### è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯\n")
        prompt_parts.append(f"- ä»£ç : {basic.get('code')}")
        prompt_parts.append(f"- åç§°: {basic.get('name')}")
        prompt_parts.append(f"- å½“å‰ä»·: {basic.get('price')}")
        prompt_parts.append(f"- æ¶¨è·Œå¹…: {basic.get('change_percent')}%")
        prompt_parts.append(f"- ä»Šæ—¥æœ€é«˜: {basic.get('high')}")
        prompt_parts.append(f"- ä»Šæ—¥æœ€ä½: {basic.get('low')}")
        prompt_parts.append(f"- æ˜¨æ”¶: {basic.get('pre_close')}")
        if basic.get("volume"):
            prompt_parts.append(f"- æˆäº¤é‡: {AIService._format_volume(int(float(basic.get('volume', 0))))}")
        if basic.get("amount"):
            prompt_parts.append(f"- æˆäº¤é¢: {AIService._format_volume(int(float(basic.get('amount', 0))))}")
        
        # 1.1 æŠ€æœ¯é¢æ•°æ®
        if extra_data:
            prompt_parts.append(f"\n### æŠ€æœ¯é¢æŒ‡æ ‡\n")
            if extra_data.get("turnover_rate") is not None:
                prompt_parts.append(f"- æ¢æ‰‹ç‡: {extra_data['turnover_rate']}%")
            if extra_data.get("volume_ratio") is not None:
                prompt_parts.append(f"- é‡æ¯”: {extra_data['volume_ratio']:.2f}")
            if extra_data.get("amplitude") is not None:
                prompt_parts.append(f"- æŒ¯å¹…: {extra_data['amplitude']:.2f}%")
            
            # å‡çº¿æ•°æ®
            ma_parts = []
            if extra_data.get("ma5"):
                ma_parts.append(f"MA5={extra_data['ma5']}")
            if extra_data.get("ma10"):
                ma_parts.append(f"MA10={extra_data['ma10']}")
            if extra_data.get("ma20"):
                ma_parts.append(f"MA20={extra_data['ma20']}")
            if extra_data.get("ma60"):
                ma_parts.append(f"MA60={extra_data['ma60']}")
            if ma_parts:
                prompt_parts.append(f"- å‡çº¿: {', '.join(ma_parts)}")
            
            # åŸºæœ¬é¢æ•°æ®
            prompt_parts.append(f"\n### åŸºæœ¬é¢æ•°æ®\n")
            if extra_data.get("pe_ratio") is not None:
                prompt_parts.append(f"- å¸‚ç›ˆç‡(PE): {extra_data['pe_ratio']:.2f}")
            if extra_data.get("pb_ratio") is not None:
                prompt_parts.append(f"- å¸‚å‡€ç‡(PB): {extra_data['pb_ratio']:.2f}")
            if extra_data.get("total_mv"):
                prompt_parts.append(f"- æ€»å¸‚å€¼: {AIService._format_volume(int(extra_data['total_mv']))}")
            if extra_data.get("circ_mv"):
                prompt_parts.append(f"- æµé€šå¸‚å€¼: {AIService._format_volume(int(extra_data['circ_mv']))}")
            if extra_data.get("industry"):
                prompt_parts.append(f"- æ‰€å±è¡Œä¸š: {extra_data['industry']}")
        
        # é¾™è™æ¦œæ•°æ®
        if dragon_tiger:
            prompt_parts.append(f"\n### é¾™è™æ¦œï¼ˆè¿‘æœŸå¼‚åŠ¨ï¼‰\n")
            prompt_parts.append("| æ—¥æœŸ | ä¸Šæ¦œåŸå›  | æ¶¨è·Œå¹… | æ¢æ‰‹ç‡ | å‡€ä¹°å…¥ |")
            prompt_parts.append("|---|---|---|---|---|")
            for item in dragon_tiger:
                net_buy = AIService._format_volume(int(item.get("net_buy", 0))) if item.get("net_buy") else "-"
                prompt_parts.append(
                    f"| {item['date']} | {item.get('reason', '-')} | "
                    f"{item.get('change_pct', '-')}% | {item.get('turnover_rate', '-')}% | {net_buy} |"
                )
        
        # 2. ç”¨æˆ·é™„åŠ ä¿¡æ¯
        if extra_info:
            prompt_parts.append(f"\n### ç”¨æˆ·é™„åŠ ä¿¡æ¯\n")
            if extra_info.get("cost_price"):
                prompt_parts.append(f"- æŒä»“æˆæœ¬: {extra_info['cost_price']}")
            if extra_info.get("position"):
                prompt_parts.append(f"- æŒä»“æ•°é‡: {extra_info['position']}")
            if extra_info.get("take_profit"):
                prompt_parts.append(f"- æ­¢ç›ˆä½ç½®: {extra_info['take_profit']}")
            if extra_info.get("stop_loss"):
                prompt_parts.append(f"- æ­¢æŸä½ç½®: {extra_info['stop_loss']}")
            if extra_info.get("extra_text"):
                prompt_parts.append(f"- è¡¥å……è¯´æ˜: \n{extra_info['extra_text']}")
        
        # 3. æ—¥Kçº¿æ•°æ®
        prompt_parts.append(f"\n### è¿‘æœŸæ—¥Kçº¿æ•°æ®\n")
        if kline_data:
            last_k = kline_data[-15:]
            prompt_parts.append(f"æœ€è¿‘ {len(last_k)} ä¸ªäº¤æ˜“æ—¥æ•°æ®:")
            
            volumes = [k["volume"] for k in kline_data[-30:] if k.get("volume")]
            avg_volume = sum(volumes) / len(volumes) if volumes else 0
            
            header = "| æ—¥æœŸ | å¼€ç›˜ | æ”¶ç›˜ | æœ€é«˜ | æœ€ä½ | æ¶¨è·Œå¹… | æˆäº¤é‡ | é‡æ¯” |"
            prompt_parts.append(header)
            prompt_parts.append("|---|---|---|---|---|---|---|---|")
            
            prev_close = None
            if len(kline_data) > 15:
                prev_close = kline_data[-16]["close"]
            
            for k in last_k:
                change = ""
                if prev_close:
                    pct = ((k["close"] - prev_close) / prev_close) * 100
                    change = f"{pct:+.2f}%"
                prev_close = k["close"]
                
                vol = k.get("volume", 0)
                vol_ratio = f"{vol / avg_volume:.2f}" if avg_volume > 0 else "-"
                vol_str = AIService._format_volume(vol)
                
                prompt_parts.append(
                    f"| {k['date']} | {k['open']} | {k['close']} | {k['high']} | {k['low']} | {change} | {vol_str} | {vol_ratio} |"
                )
        
        # 4. å¤§ç›˜æ•°æ®
        if market_data:
            prompt_parts.append(f"\n### å¤§ç›˜ç¯å¢ƒ\n")
            index_data = market_data.get("index", {})
            if index_data:
                prompt_parts.append("**ä¸»è¦æŒ‡æ•°:**")
                for code, idx in index_data.items():
                    if idx:
                        prompt_parts.append(
                            f"- {idx.get('name', code)}: {idx.get('price')} ({idx.get('change_percent')}%)"
                        )
        
        # 5. ç”¨æˆ·äº¤æ˜“è®°å½•
        if trade_history:
            prompt_parts.append(f"\n### ç”¨æˆ·äº¤æ˜“è®°å½•\n")
            prompt_parts.append("| æ—¶é—´ | ç±»å‹ | ä»·æ ¼ | æ‰‹æ•° | æ“ä½œåŸå›  |")
            prompt_parts.append("|---|---|---|---|---|")
            for t in trade_history:
                type_map = {"B": "ä¹°å…¥", "S": "å–å‡º", "T": "åšT"}
                type_str = type_map.get(t["type"], t["type"])
                prompt_parts.append(
                    f"| {t['trade_time']} | {type_str} | {t['price']} | {t['quantity']} | {t['reason']} |"
                )
        
        # 6. å†å² AI åˆ†æè®°å½•
        if ai_history:
            prompt_parts.append(f"\n### å†å² AI åˆ†æè®°å½•\n")
            prompt_parts.append("| æ—¶é—´ | ä¿¡å· | æ‘˜è¦ |")
            prompt_parts.append("|---|---|---|")
            signal_map = {"bullish": "çœ‹æ¶¨ğŸ“ˆ", "cautious": "è°¨æ…âš ï¸", "bearish": "çœ‹è·ŒğŸ“‰"}
            for a in ai_history:
                signal_str = signal_map.get(a["signal"], a["signal"])
                prompt_parts.append(f"| {a['datetime']} | {signal_str} | {a['summary']} |")
        
        # 7. èµ„é‡‘æµå‘æ•°æ®
        if money_flow:
            prompt_parts.append(f"\n### èµ„é‡‘æµå‘ï¼ˆæœ€è¿‘{money_flow_days}å¤©ï¼‰\n")
            
            daily_flow = {}
            for item in money_flow:
                time_str = item.get("time", "")
                date = time_str.split(" ")[0] if " " in time_str else time_str[:10]
                if date not in daily_flow:
                    daily_flow[date] = {"main_in": 0, "big_in": 0, "mid_in": 0, "small_in": 0, "super_in": 0}
                daily_flow[date]["main_in"] += item.get("main_in", 0)
                daily_flow[date]["big_in"] += item.get("big_in", 0)
                daily_flow[date]["mid_in"] += item.get("mid_in", 0)
                daily_flow[date]["small_in"] += item.get("small_in", 0)
                daily_flow[date]["super_in"] += item.get("super_in", 0)
            
            sorted_dates = sorted(daily_flow.keys(), reverse=True)[:money_flow_days]
            
            if sorted_dates:
                prompt_parts.append("| æ—¥æœŸ | ä¸»åŠ›å‡€æµå…¥ | è¶…å¤§å• | å¤§å• | ä¸­å• | å°å• |")
                prompt_parts.append("|---|---|---|---|---|---|")
                
                for date in sorted(sorted_dates):
                    flow = daily_flow[date]
                    main_net = flow["super_in"] + flow["big_in"]
                    prompt_parts.append(
                        f"| {date} | {AIService._format_volume(int(main_net))} | "
                        f"{AIService._format_volume(int(flow['super_in']))} | "
                        f"{AIService._format_volume(int(flow['big_in']))} | "
                        f"{AIService._format_volume(int(flow['mid_in']))} | "
                        f"{AIService._format_volume(int(flow['small_in']))} |"
                    )
        
        # 8. åˆ†æè¦æ±‚
        prompt_parts.append(f"\n### åˆ†æè¦æ±‚\n")
        prompt_parts.append("è¯·é‡ç‚¹åˆ†æï¼š")
        prompt_parts.append("1. ä»·é‡é…åˆå…³ç³»")
        prompt_parts.append("2. æˆäº¤é‡å¼‚åŠ¨æƒ…å†µ")
        prompt_parts.append("3. èµ„é‡‘æµå‘åˆ†æ")
        prompt_parts.append("4. å‡çº¿ç³»ç»Ÿåˆ†æ")
        prompt_parts.append("5. ä¼°å€¼åˆ†æ")
        prompt_parts.append("6. ç»“åˆå¤§ç›˜ç¯å¢ƒåˆ¤æ–­")
        prompt_parts.append("7. çŸ­æœŸè¶‹åŠ¿åˆ¤æ–­")
        prompt_parts.append("8. æ“ä½œå»ºè®®")
        
        return "\n".join(prompt_parts)
